# Kafka-Python 프로그래밍



## 가상환경 접속

```powershell
lab26@ip-000-00-00-0:~/kafka_lab26$ source activate lab26_env
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ 
```

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ cd ..
(lab26_env) lab26@ip-000-00-00-0:~$ cd kafka_2.13-3.2.0/
(lab26_env) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties
(lab26_env) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-server-start.sh -daemon ./config/server.properties 
(lab26_env) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ netstat -an | grep 2126
(lab26_env) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ netstat -an | grep 9026
```



## 실습1

> **`consumer.py`와 `producer.py` 파일 만들기**



### 1.`producer.py`  에서 진행

```python
from kafka import KafkaProducer

# 브로커 생성시에는 브로커의 호스트들의 리스트를 준비한다.
# 한개만 알아도 상관없지만 모든 브로커들의 리스트를 입력하는것을 권장
BROKER_SERVER = ["localhost:9026"]
TOPIC_NAME = "first_lab26_topic"

# 프로듀스 생성
producer = KafkaProducer(bootstrap_servers=BROKER_SERVER)

# 브로커에게 토픽에 맞는 데이터를 전송
producer.send(TOPIC_NAME, b'Hello world Kafka!')

# 버퍼 스트림 제거(안해도 상관없는데 권장함.)
producer.flush()
```



+ 버퍼 스트림의 지꺼기 제거 -> `producer.flush()` 
  + 버퍼에 남아있는 찌꺼기 데이터를 없애주는 역할
  + 버퍼 초기화 라고도함.
  + 전송이 끝났는데 찌꺼기가 남아있어 전송완료로 인식하지 못할수있어서 써주는게 좋다.



### 2.`consumer.py` 에서 작업진행

```python
from kafka import KafkaConsumer

BROKER_SERVER = ["localhost:9026"]
TOPIC_NAME = "first_lab26_topic"

consumer = KafkaConsumer(TOPIC_NAME, bootstrap_servers=BROKER_SERVER)

# consumer는 파이썬의 Generator로 구성되어있다.
print("Wait....")

for message in consumer:
    print(message)
    
print("Done....")
```



### 3.터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python consumer.py
```

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python producer.py
```



### 4.서버 종료 

(브로커 먼저 종료시켜주고 그다음 주키퍼 종료)

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-server-stop.sh
(lab26_env) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/zookeeper-server-stop.sh
```



### +코드보기

[producer.py 확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/producer.py)

[consumer.py 확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/consumer.py)



# Kafka-Docker

> 가상화 도구
>
> > 리눅스 os를 사용할수있게 해주는 가상화 도구



## 실습2

> **`docker-compose`만들기**
>
> > **`docker-compose.yml` 파일 만들기**



![image-20220524101756318](220524_s.assets/image-20220524101756318-16533550779061.png)

`VSCode`의`Extensions`에서 `docker` 설치



### 1.`docker-compose.yml`

+ 주석쓸때 바로 옆에다가 주석쓰면 오류날수있으니 주의. 

+ 띄어쓰기나 들여쓰기 할때 조심하기

```yml
version: '3'
services:
  zookeeper:
    image: zookeeper:3.7
    hostname: zookeeper
    ports:
      - "2126:2181" # 포트 포워딩, 2126으로 접속요청을 하게되면 자동으로 2181(기본포트)로 들어갈수있게 설정해주는것.
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
    # 로컬환경과 싱크를 맞춰주는 옵션
    volumes:
      - ./data/zookeeper/data:/data
      - ./data/zookeeper/datalog:/datalogco
  # 브로커 설정 (브로커 3개 설정할 예정)
  kafka1:
    image: confluentinc/cp-kafka:7.0.0  # 7.0.0 버전을 사용하겠다.
    hostname: kafka1
    ports: # 원래 쓰던 포트 x3
      - "9078:9091"  # 9091는 카프카 고정 포트
    environment: 
      # 리스너는 접속하기를 기다리는 역할
      # 내부에서 기다릴 주소와 외부에서 기다릴 주소를 지정해준다.
      # kafka1:19091,LISTENER_DOCKER_EXTERNAL 쓸때 , 후에 띄어쓰기하면 오류남.
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19091,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9078 
      # 보안 세팅
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSET_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./data/kafka1/data:/tmp/kafka-logs
    depends_on:
      - zookeeper # 얘가 실행되야지만 kafka1을 실행시키겠다 라는것. 
  # kafka 2,3번은 1번 내용 복사한뒤 포트번호나 브로커 아이디들만 바꿔준다.
  kafka2:
    image: confluentinc/cp-kafka:7.0.0
    hostname: kafka2
    ports: 
      - "9079:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9079
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSET_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./data/kafka2/data:/tmp/kafka-logs
    depends_on:
      - zookeeper
  kafka3:
    image: confluentinc/cp-kafka:7.0.0
    hostname: kafka3
    ports: 
      - "9080:9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9080
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 3
      KAFKA_OFFSET_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./data/kafka3/data:/tmp/kafka-logs
    depends_on:
      - zookeeper
```



image: <u>zookeeper</u>:3.7 에서 `zookeeper`를 누르면 이런 창이 뜬다.

![image-20220524160526849](220524_s.assets/image-20220524160526849.png)



image: <u>confluentinc/cp-kafka</u>:7.0.0 에서 `confluentinc/cp-kafka` 누르면 

마찬가지로 창이 뜬다.

![image-20220524160817143](220524_s.assets/image-20220524160817143.png)



+ `topic` 생성

다른 터미널 한개 더 열어서 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ docker exec -it kafkalab26_kafka1_1 kafka-topics --bootstrap-server=localhost:19091 --create --topic first-lab26-cluster-topic --partitions 1 --replication-factor 1

# 출력결과
Created topic first-lab26-cluster-topic.
```



+ 파일 및 폴더 생성

  1. `cluster_consumer.py`
  
  
    2. `cluster_producer.py`
  
  
  3. `trips` 폴더 생성

  



### 2.`cluster_consumer.py` 에서 작업

```python
from kafka import KafkaConsumer

# docker에서 사용한 포트 번호들 입력
# Broker 목록은 모두 설정하는것이 좋다.
BROKERS = ["localhost:9078", "localhost:9079", "localhost:9080"]
TOPIC_NAME = "first-lab26-cluster-topic"

consumer = KafkaConsumer(TOPIC_NAME, bootstrap_servers=BROKERS)

print("Wait...")

for message in consumer:
    print(message)

print("Done...")

```



+ 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python cluster_consumer.py

# 출력결과
Wait...

```



### 3.`cluster_producer.py` 작업

```python
from kafka import KafkaProducer

BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"]
TOPIC_NAME = "first-lab26-cluster-topic"

producer = KafkaProducer(
    bootstrap_servers=BROKERS
)

producer.send(TOPIC_NAME, b"Hello Kafka!!!")
producer.flush()
```



+ 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python cluster_producer.py
```



#### debugging

> 포트 번호 수정



+ `docker-compose` 수정

```yml
version: '3'
services:
  zookeeper:
    image: zookeeper:3.7
    hostname: zookeeper
    ports:
      - "2126:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
    volumes:
      - ./data/zookeeper/data:/data
      - ./data/zookeeper/datalog:/datalogco
  kafka1:
    image: confluentinc/cp-kafka:7.0.0
    hostname: kafka1
    ports: 
      - "8978:8978"  # 수정
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19091,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:8978 # 수정
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSET_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./data/kafka1/data:/tmp/kafka-logs
    depends_on:
      - zookeeper
  kafka2:
    image: confluentinc/cp-kafka:7.0.0
    hostname: kafka2
    ports: 
      - "8979:8979"  # 수정
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:8979 # 수정
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSET_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./data/kafka2/data:/tmp/kafka-logs
    depends_on:
      - zookeeper
  kafka3:
    image: confluentinc/cp-kafka:7.0.0
    hostname: kafka3
    ports: 
      - "8980:8980"  # 수정
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:8980 # 수정
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 3
      KAFKA_OFFSET_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./data/kafka3/data:/tmp/kafka-logs
    depends_on:
      - zookeeper
```



**수정후에 도커 다시 실행**

> `python cluster_consumer.py` 실행할때 `${DOCKER_HOST_IP:-127.0.0.1}:9078` 로 접속이 안되서 내부포트인 `8978, 8979, 8980` 으로 변경후 다시 도커실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ cd ..
(lab26_env) lab26@ip-000-00-00-0:~$ cd kafka_lab26
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ docker-compose up # 도커 실행
```



+ `cluster_consumer.py` 도 포트번호 수정

```python
BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"] # 수정
```



+ `cluster_producer.py` 도 포트번호 수정

```python
BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"] # 수정
```



+ 터미널 실행

```powershell
# 터미널 1에서 실행
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python cluster_consumer.py

# 터미널 2에서 실행
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python cluster_producer.py
```

이제 실행 잘 된다.



### + 코드보기

[docker-compose.yml 확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/docker-compose.yml)

[cluster_producer.py 확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/cluster_producer.py)

[cluster_consumer.py 확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/cluster_consumer.py)



## 실습3

> 어플리케이션 개발 연습해보기
>
> > `yellow_tripdata_2021-01.csv` 의 내용을 실시간으로 읽어오기



### 파일 생성

1. `trips_consumer.py`

2. `trips_producer.py`



### 1.`trips_producer.py`

```python
# CSV 파일을 열어서 한줄 한줄 스트리밍
from kafka import KafkaProducer

import csv
import json
import time

BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"]
TOPIC_NAME = "first-lab26-cluster-topic"

producer = KafkaProducer(bootstrap_servers=BROKERS)

# csv 파일 열기
with open("./trips/yellow_tripdata_2021-01.csv") as f:
    reader = csv.reader(f)  # csv 를 한줄 한줄 읽게 도와주는 역할

    # reader 에서 한줄씩 읽어오기
    for row in reader:
        time.sleep(0.5)  # 0.5초씩 딜레이 주면서 실행하게끔 (안해도 되는데 더 잘 확인하기위해)
        producer.send(TOPIC_NAME, json.dumps(row).encode("utf-8"))
        print(row)
```



+ 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python trips_producer.py
```



### 2.`trips_consumer.py`

```python
from kafka import KafkaConsumer
import json

BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"]
TOPIC_NAME = "first-lab26-cluster-topic"

consumer = KafkaConsumer(TOPIC_NAME, bootstrap_servers=BROKERS)

for message in consumer:
    # message에서 value를 추출하면 Producer가 보낸값을 보여줌
    row = json.loads(message.value.decode())
    print(row)
```



+ 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ python trips_consumer.py
```



### 3.`kafdrop` 추가

> **`docker-compose.yml` 에서 `kafdrop` 추가해주기**



```yml
# 추가해주기
  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports: 
      - "9000:9000"
    environment:
      KAFKA_BROKER_CONNECT: "kafka1:19091"
    depends_on:
      - kafka1
      - kafka2
      - kafka3
```



주소창에 `http://[AWS인스턴스 ip주소]:[포트번호]/` 들어가면 이런 창이 뜬다.

`Kafdrop` 이 활성화 된다.

![image-20220524133038998](220524_s.assets/image-20220524133038998.png)

+ `Kafdrop` 는 UI 화면을 제공한다.



![image-20220524133408259](220524_s.assets/image-20220524133408259.png)

+ UI 상에서 토픽 지우는것도 가능



![image-20220524133533089](220524_s.assets/image-20220524133533089.png)

+ 프로듀서를 활성화하면 토픽 메세지도 볼수있다.



![image-20220524133708053](220524_s.assets/image-20220524133708053.png)

+ UI 상에서 토픽생성도 가능



### + 코드보기

[**kafdrop** 코드 확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/docker-compose.yml)

[trips_producer.py확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/trips_producer.py)

[trips_consumer.py 확인](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/kafka_lab26/trips_consumer.py)





# 실습4

> **카드 비정상 이용거래데이터 선별 프로젝트**



![image-20220524231527997](220524_s.assets/image-20220524231527997.png)





## `fruad` 폴더 추가

**파일생성**

1. `payment_producer.py`
2. `legit_processor.py`
3. `fraud_processor.py`
4. `fraud_detector.py`



## 1.`Topic` 생성

> **터미널에서 토픽부터 만들고 시작**



```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ docker exec -it kafkalab26_kafka1_1 kafka-topics --bootstrap-server=localhost:19091 --create --topic payments --partitions 1 --replication-factor 1

(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ docker exec -it kafkalab26_kafka1_1 kafka-topics --bootstrap-server=localhost:19091 --create --topic fraud_payments --partitions 1 --replication-factor 1

(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ docker exec -it kafkalab26_kafka1_1 kafka-topics --bootstrap-server=localhost:19091 --create --topic legit_payments --partitions 1 --replication-factor 1

(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ docker exec -it kafkalab26_kafka1_1 kafka-topics --bootstrap-server=localhost:19091 --list

# 출력결과
first-lab26-cluster-topic
fraud_payments
legit_payments
payments
second-lab26-topic
```



## 2.`payment_producer.py`

```python
from kafka import KafkaProducer
import datetime
import pytz  # 패키지 없으면 'pip install pytz' 로 설치
import time
import random
import json

# 토픽이름부터 정의
TOPIC_NAME = "payments"
BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"]

# Producer 생성
producer = KafkaProducer(bootstrap_servers=BROKERS)

# 현재시간을 Asia/Seoul timezone에 맞춰서 생성
def get_seoul_date():
    utc_now = pytz.utc.localize(datetime.datetime.utcnow())
    kst_now = utc_now.astimezone(pytz.timezone("Asia/Seoul"))
    d = kst_now.strftime("%m/%d/%Y")
    t = kst_now.strftime("%H:%M:%S")
    return d, t

print(get_seoul_date())
```



현재시간 잘 나오는지 확인

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26$ cd fraud
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26/fraud$ python payment_producer.py

# 출력결과
('05/24/2022', '14:16:47')
```

잘 나오니까 `print(get_seoul_date())` 지우고 다시 코드 작성



```python
# 결제정보 데이터 생성기. 랜덤하게 결제 정보를 만들어준다.
def generate_payment_data():
    # 데이터 소스로부터 데이터를 끌어오는 기능을 만들어주면 된다.
    # 크롤러나 다른 데이터 레이크에서 데이터를 가져오면 됨.
    payment_type = random.choice(['롯데', '하나', '삼성', '현대', '비트코인'])
    amount = random.randint(1000, 1000000)

    to = random.choice(["me", "mom", "dad", "stranger"])

    return payment_type, amount, to

# 데이터 발생 및 스트리밍
while True:
    d, t = get_seoul_date()
    payment_type, amount, to = generate_payment_data()

    # 스트리밍할 데이터 조립(json으로)
    new_data = {
        "DATE": d,
        "TIME": t,
        "PAYMENT_TYPE": payment_type,
        "AMOUNT": amount,
        "TO": to
    }

    # 프로듀싱
    producer.send(TOPIC_NAME, json.dumps(new_data).encode("utf-8"))
    print(new_data)
    time.sleep(1)
```



+ 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26/fraud$ python payment_producer.py

# 출력결과
{'DATE': '05/24/2022', 'TIME': '14:28:56', 'PAYMENT_TYPE': '현대', 'AMOUNT': 100833, 'TO': 'me'}
{'DATE': '05/24/2022', 'TIME': '14:28:57', 'PAYMENT_TYPE': '하나', 'AMOUNT': 576766, 'TO': 'me'}
{'DATE': '05/24/2022', 'TIME': '14:28:58', 'PAYMENT_TYPE': '비트코인', 'AMOUNT': 460113, 'TO': 'mom'}
{'DATE': '05/24/2022', 'TIME': '14:28:59', 'PAYMENT_TYPE': '비트코인', 'AMOUNT': 967840, 'TO': 'me'}
...
```



## 3.`fraud_detector.py`

> **이상탐지 프로그램 만들기**



```python
# payment_producer 한테서 데이터를 Consume
# 정상데이터 -> legit_processor로 프로듀싱
# 이상데이터 -> fraud_processor로 프로듀싱

from kafka import KafkaConsumer, KafkaProducer
import json

PAYMENT_TOPIC = "payments"
FRAUD_TOPIC = "fraud_payments"
LEGIT_TOPIC = "legit_payments"

BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"]

consumer = KafkaConsumer(PAYMENT_TOPIC, bootstrap_servers=BROKERS)

# 이상한 결제 데이터의 기준을 정의
def is_suspicious(message):
    # stranger가 결제를 했거나, 비트코인으로 결제를 했다면 의심스러운 사람으로 정의
    if message["TO"] == "stranger" or message["PAYMENT_TYPE"] == "비트코인":
        return True
    else:
        return False

# consumer가 메세지를 잘 받아오는지 테스트
for message in consumer:
    msg = json,loads(message.value.decode())
    print(is_suspicious(msg), msg["PAYMENT_TYPE"], msg["TO"])
```



`msg` 출력 잘 되는지 확인

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26/fraud$ python fraud_detector.py

# 출력결과
False 하나 dad
True 비트코인 me
False 삼성 dad
False 하나 mom
True 롯데 stranger
False 현대 mom
True 비트코인 dad
False 롯데 mom
...
```

실행이 잘되면 이제 `producer` 코드도 추가



정상거래와 비정상거래로 나눠서 프로듀싱

```python
producer = KafkaProducer(bootstrap_servers=BROKERS)   # 추가

for message in consumer:
    msg = json.loads(message.value.decode())

    if is_suspicious(msg):    # 추가
        producer.send(FRAUD_TOPIC, json.dumps(msg).encode("utf-8"))
    else:
        producer.send(LEGIT_TOPIC, json.dumps(msg).encode("utf-8"))

    print(is_suspicious(msg), msg["PAYMENT_TYPE"], msg["TO"])
```



+ 다시 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26/fraud$ python fraud_detector.py
```



+ `Kafdrop`으로 확인

![image-20220524145103948](220524_s.assets/image-20220524145103948.png)



![image-20220524144949189](220524_s.assets/image-20220524144949189.png)

`Kafdrop`으로 확인시 잘 나눠져서 들어간것을 확인할수있음.



## 4.`legit_processor.py`

> **정상데이터**

```python
from kafka import KafkaConsumer
import json

LEGIT_TOPIC = "legit_payments"
BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"]

consumer = KafkaConsumer(LEGIT_TOPIC, bootstrap_servers=BROKERS)

for message in consumer:
    msg = json.loads(message.value.decode())
    payment_type = msg["PAYMENT_TYPE"]
    payment_date = msg["DATE"]
    payment_time = msg["TIME"]
    amount = msg["AMOUNT"]
    to = msg["TO"]
    print(f"[{payment_type}] {payment_date} {payment_time} << {to} - {amount} >>")
```



+ 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26/fraud$ python legit_processor.py

# 출력결과
[현대] 05/24/2022 15:07:32 << me - 71202 >>
[현대] 05/24/2022 15:07:33 << mom - 331725 >>
[삼성] 05/24/2022 15:07:34 << mom - 777896 >>
[삼성] 05/24/2022 15:07:37 << mom - 460126 >>
[롯데] 05/24/2022 15:07:38 << dad - 941947 >>
...
```



## 5.`fraud_processor.py`

> **비정상 데이터**
>
> > 여기서 슬랙으로 비정상 거래 발생시 알림메세지 오게끔하는 코드도 넣을수있음.



```python
from kafka import KafkaConsumer
import json

FRAUD_TOPIC = "fraud_payments"
BROKERS = ["localhost:8978", "localhost:8979", "localhost:8980"]

consumer = KafkaConsumer(FRAUD_TOPIC, bootstrap_servers=BROKERS)

for message in consumer:
    msg = json.loads(message.value.decode())
    payment_type = msg["PAYMENT_TYPE"]
    payment_date = msg["DATE"]
    payment_time = msg["TIME"]
    amount = msg["AMOUNT"]
    to = msg["TO"]
    print(f"이상거래 - [{payment_type}] {payment_date} {payment_time} << {to} - {amount} >>")
```



+ 터미널 실행

```powershell
(lab26_env) lab26@ip-000-00-00-0:~/kafka_lab26/fraud$ python fraud_processor.py

# 출력결과
이상거래 - [롯데] 05/24/2022 15:14:09 << stranger - 213946 >>
이상거래 - [현대] 05/24/2022 15:14:14 << stranger - 427501 >>
이상거래 - [하나] 05/24/2022 15:14:22 << stranger - 679587 >>
이상거래 - [롯데] 05/24/2022 15:14:23 << stranger - 269753 >>
이상거래 - [하나] 05/24/2022 15:14:24 << stranger - 630727 >>
...
```



## + 코드보기

[결제정보 프로듀싱](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/fraud/payment_producer.py)

[이상거래 탐지 프로그램](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/fraud/fraud_detector.py)

[정상 데이터 Consumer](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/fraud/legit_processor.py)

[비정상(이상거래) 데이터 Consumer](https://github.com/suyeee/todo_study/blob/master/220524_s.assets/fraud/fraud_processor.py)



*****

