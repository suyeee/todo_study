# 스파이더 프로그램
**단축키**

+ `블럭 + F9`
  + 코드실행
+ help 창
  + `ctrl + i`



# 예제2



## 1번

문제

```python
# =============================================================================
# 1.해당 데이터에 대한 EDA를 수행하고, 여성으로 혈압이 High, Cholesterol이 Normal인
# 환자의 전체에 대비한 비율이 얼마인지 소수점 네 번째 자리에서 반올림하여 소수점 셋째
# 자리까지 기술하시오. (답안 예시) 0.123
# =============================================================================
```



```python
# value_counts: 지정한 컬럼순으로 구룹핑을 해줌
# normalize=True : 전체 대비 빈도를 확률로 나타내줌.
q1 = data2[['Sex', 'BP','Cholesterol']].value_counts(normalize=True)
ql[('F', 'HIGH', 'NORMAL')]

# 답 : 0.105

# 참고
# 피벗테이블
# 빈도를 구하는 함수
# aggfunc=len() : 
# aggfunc= 'count' : 디폴트값
# normalize : values 값을 지정해야 사용가능
# normalize='all' : 디폴트값
# normalize=1 : 열방향의 합이 1이 되도록 확률을 구함.
# normalize=0 : 행방향
pd.crosstab(index=[data2['Sex'], data2['BP']],
           columns = data2['Cholesterol'],
           values = None,
           aggfunc= 'count',
           normalize='all')
```



**피벗 테이블 이용**

```python
q1_2 = pd.pivot_table(data2,
                     index=['Sex','BP','Cholesterol'],
                     values='Sex', # 아무거나 벨류로 지정가능. 빈도수만 구하면되니까
                     aggfunc='count') / len(data2)

# / len(data2) : 전체 대비 특정값들이 존재하는 행들의 확률
# 피벗테이블은 normalize 기능이 없어서 직접 확률 구해줘야됨. -> / len(data2)

```



## 2번

문제

```python
# =============================================================================
# 2. Age, Sex, BP, Cholesterol 및 Na_to_k 값이 Drug 타입에 영향을 미치는지 확인하기
# 위하여 아래와 같이 데이터를 변환하고 분석을 수행하시오. 
# - Age_gr 컬럼을 만들고, Age가 20 미만은 ‘10’, 20부터 30 미만은 ‘20’, 30부터 40 미만은
# ‘30’, 40부터 50 미만은 ‘40’, 50부터 60 미만은 ‘50’, 60이상은 ‘60’으로 변환하시오. 
# - Na_K_gr 컬럼을 만들고 Na_to_k 값이 10이하는 ‘Lv1’, 20이하는 ‘Lv2’, 30이하는 ‘Lv3’, 30 
# 초과는 ‘Lv4’로 변환하시오.
# - Sex, BP, Cholesterol, Age_gr, Na_K_gr이 Drug 변수와 영향이 있는지 독립성 검정을
# 수행하시오.
# - 검정 수행 결과, Drug 타입과 연관성이 있는 변수는 몇 개인가? 연관성이 있는 변수
# 가운데 가장 큰 p-value를 찾아 소수점 여섯 번째 자리 이하는 버리고 소수점 다섯
# 번째 자리까지 기술하시오.
# (답안 예시) 3, 1.23456
# =============================================================================
```



**np.where(조건, 참, 거짓)** 이용

```python
# 선형회귀 분석 전 체크 : 두 변수간의 상관관계 존재 여부 확인
# 상관관계가 없다면 전처리 후 분석

# 분류 분석 : 범주형 변수간의 관계성이 존재하는지 확인 -> 카이스퀘어 검정

# 1. 파생변수(new 변수) 생성 : Age_gr, Na_K_gr

q2 = data2.copy() # 원본 보호

# np.where(조건) :  조건이 True 인 위치번호 리턴 (인덱스 값 리턴)
# np.where(조건, 참, 거짓) 
# 거짓의 조건을 넣는 곳에 함수안에 함수를 사용
q2['Age_gr'] = np.where(q2['Age'] < 20, 10,
                	np.where(q2['Age'] < 30 , 20,
                        np.where(q2['Age'] < 40, 30,
                             np.where(q2['Age'] < 50,40,
                                  np.where(q2['Age'] < 60, 50, 60)))))


--------------------------------------------------------------------------------
# 결측치가 있는지 확인후 처리하는 방법
# np.nan : nan 값으로 다시 채우기
np.where(q2['Age'].isna(), np.nan, 
        np.where(q2['Age'] < 20, 10,
                	np.where(q2['Age'] < 30 , 20,
                        np.where(q2['Age'] < 40, 30,
                             np.where(q2['Age'] < 50,40,
                                  np.where(q2['Age'] < 60, 50, 60))))))
------------------------------------------------------------------------------------

q2['Na_K_gr'] = np.where(q2['Na_to_K'] <= 10, 'Lv1',
                     np.where(q2['Na_to_K'] <= 20, 'Lv2',
                           np.where(q2['Na_to_K'] <= 30, 'Lv3', 'Lv4')))

# 2. 카이스퀘어 검정 수행 (적합성/ 독립성/ 동질성)
# (1) 빈도

# - 관측 빈도
tab = pd.crosstab(index=q2['Sex'],
                 columns=q2['Drug'])

# (2) 두 변수 간의 카이스퀘어 검정

from scipy.stats import chi2_contingency

chi_out= chi2_contingency(tab)

pvalue = chi_out[1]
pvalue < 0.05 # 결과 False 로 나왔음.

# H0(귀무가설) : 두변수는 독립이다. => pvalue >= 0.05 => 귀무가설 채택
# H1(대립가설) : 두 변수는 독립이 아니다 (관계성이 존재한다) => pvalue < 0.05  => 대립가설 채택

# 결론 : 유의수준 0.05 하에서 p-value 가 0.05이상 이므로 귀무가설을 기각할수없다.
# 즉, 두 변수는 독립이다.


# (3) 변수별로 반복 수행(for)

from scipy.stats import chi2_contingency

var_list = ['Sex', 'BP', 'Cholesterol', 'Age_gr', 'Na_K_gr']


q2_out=[]

for i in var_list:
    tab = pd.crosstab(index=q2[i],columns=q2['Drug'])
    chi_out= chi2_contingency(tab)
    pvalue = chi_out[1]
    q2_out.append([i, pvalue]) # pvalue 가 누적이 되게끔 설계
    
    
q2_out=pd.DataFrame(q2_out, columns=['var', 'pvalue'])

q2_out2 = q2_out[q2_out.pvalue < 0.05] # 마스킹

len(q2_out2) # 결과 4

q2_out2.pvalue.max() # 결과 0.00070
# 또는 int(q2_out2.pvalue.max() * 100000)/100000

# 답: 4, 0.00070
    
```



**카이스퀘어 검정**

> 설명은 강의자료 참고



**표준오차**

> 설명은 강의자료 참고



**기대빈도**

> 설명은 강의자료 참고



**독립성 검정**

+ 적합성은 변수 1개

- 독립성/ 동질성 검정은 변수 2개 필요





**표본을 여러번 뽑아 각각의 카이스퀘어 통계량을 구한다.**



+ H0 : 귀무가설

+ H1: 대립가설

+ x 바 (표본의 평균) : 정규분포를 따름 -> 중심극한의 정리

+ 기각역 : 귀무가설을 기각해도 되는 구간

+ p-value 0.05 유의수준하에서 의사결정

+ p-value < 0.05 : 귀무가설 기각 , 두 변수는 서로 관계가 있다.

+ p-value > 0.05 : 귀무가설 채택, 두 변수는 독립이다.



## 3번

문제

```python
# =============================================================================
# 3.Sex, BP, Cholesterol 등 세 개의 변수를 다음과 같이 변환하고 의사결정나무를 이용한
# 분석을 수행하시오.
# - Sex는 M을 0, F를 1로 변환하여 Sex_cd 변수 생성
# - BP는 LOW는 0, NORMAL은 1 그리고 HIGH는 2로 변환하여 BP_cd 변수 생성
# - Cholesterol은 NORMAL은 0, HIGH는 1로 변환하여 Ch_cd 생성
# - Age, Na_to_k, Sex_cd, BP_cd, Ch_cd를 Feature로, Drug을 Label로 하여 의사결정나무를
# 수행하고 Root Node의 split feature와 split value를 기술하시오. 
# 이 때 split value는 소수점 셋째 자리까지 반올림하여 기술하시오. (답안 예시) Age, 
# 12.345
# =============================================================================
```



**의사결정나무**

> 설명은 강의자료 참고



[알고있어야하는것]

1. 불순도

   + 불순도가 낮게 같은 그룹끼리 묶일수 있도록
   + 카이스퀘어 통계량 활용 (숫자가 크면 클수록 좋다)
   + 지니지수와 엔트로피는 숫자가 작을수록 좋다
   + 지니지수

   $$
   1-\sum_{i=1}^n Pi^2
   $$

   + 자식노드의 지니지수가 작아지는 방향으로 뻗어나감
   + 깊이(depth)를 설정하지 않는 경우 불순도가 0이 될때가지 수행함.
   + 오버피팅(과대적합)을 완화하기위해 가지치기를 진행함.
   + leaf의 샘플의 수를 기준으로 제약을함. 

2. Information Gain
   + 아래쪽으로 갈수록 변동량이 미미한경우가 있는데 변동량이 미미한 경우 더이상 성장을 못하게 제약을 걸수도 있다.
3. Feature Importance
   + 보통은 중요한 변수의 경우 상단에 배치함.
   + 얼마만큼 자주 언급되는 변수이냐에 따라 변수 중요도가 측정이 되기도함.
   + 중요변수라고 해서 무조건 상단에 있는것만은 아님.

+ 의사결정나무는 아래로 갈수록 분산이 작아진다. 유사한 그룹끼리 묶이니까



```python
# 1. 변수 변환 (범주형 변수 -> 수치형으로)
q3 = data2.copy()

q3['Sex_cd'] = np.where(q3.Sex == 'M', 0, 1)  # 변수 생성시 결측치 처리 고려하기
q3['BP_cd'] = np.where(q3.BP == 'LOW', 0, np.where(q3.BP == 'NORMAL', 1, 2))
q3['Ch_cd'] = np.where(q3.Cholesterol == 'NORMAL', 0, 1)

# 2. 의사결정나무 수행
from sklearn.tree import DecisionTreeClassifier , plot_tree, export_text

var_list=['Age', 'Na_to_k', 'Sex_cd', 'BP_cd', 'Ch_cd']

#DecisionTreeClassifier(random_state=...) : 규칙을 일정하게 사용할수있음.
dt = DecisionTreeClassifier().fit(q3[var_list], q3['Drug'])

dir(dt)
pd.Series(dt.feature_importances_, index=var_list)

# 3. 시각화 및 텍스트로 룰을 확인
# 어떤 방식으로 데이터가 나눠져있는지 확인
plot_tree(dt, feature_names = var_list,
          class_names=list(q3.Drug.unique()),
          max_depth=2,
          precision=3,
          fontsize=7)

# 답 : Na_to_k, 14.829

print(export_text(dt, feature_names = var_list, decimals=3))
# print 안쓰고 export_text(dt, feature_names = var_list) 하면 보기힘들게 나옴.


```



# 예제3

```python
import pandas as pd
import numpy as np

data3 = pd.read_csv('Dataset_03.csv')
data3.columns
#['long_hair', 'forehead_width_cm', 'forehead_height_cm', 'nose_wide',
       'nose_long', 'lips_thin', 'distance_nose_to_lip_long', 'gender',
       'forehead_ratio']
```



## 1번

```python
# =============================================================================
# 1.이마의 폭(forehead_width_cm)과 높이(forehead_height_cm) 사이의
# 비율(forehead_ratio)에 대해서 평균으로부터 3 표준편차 밖의 경우를 이상치로
# 정의할 때, 이상치에 해당하는 데이터는 몇 개인가? (답안 예시) 10
# =============================================================================
```

+ 산술평균은 이상치에 영향을 많이 받음

+ 이상치에 영향을 덜 받도록 중앙값을 이용하기도함.

+ 또는 이상치를 제거하고 평균을 구하기도함.



```python
q1 = data3.copy()
q1['forehead_ratio'] = q1['forehead_width_cm']/ q1['forehead_height_cm']

xbar = q1['forehead_ratio'].mean()
sd = q1['forehead_ratio'].std()

# 3 표준편차 밖의 경우
LB = xbar - (3 * sd) # low 바운드
UB = xbar + (3 * sd) # upper 바운드

q1[(q1['forehead_ratio'] < LB) | (q1['forehead_ratio'] > UB)] # 마스킹
# 또는 ((q1['forehead_ratio'] < LB) | (q1['forehead_ratio'] > UB)).sum()

# 답: 3
```





## 2번

```python
# =============================================================================
# 2.성별에 따라 forehead_ratio 평균에 차이가 있는지 적절한 통계 검정을 수행하시오.
# - 검정은 이분산을 가정하고 수행한다.
# - 검정통계량의 추정치는 절대값을 취한 후 소수점 셋째 자리까지 반올림하여
# 기술하시오.
# - 신뢰수준 99%에서 양측 검정을 수행하고 결과는 귀무가설 기각의 경우 Y로, 그렇지
# 않을 경우 N으로 답하시오. (답안 예시) 1.234, Y
# =============================================================================
```



분산 고려 -> 독립인 T 검정

```python
from scipy.stats import ttest_1samp, ttest_ind, ttest_rel
from scipy.stats import bartlett, levene # 등분산 검정

# 독립인 이표본 t 검정 절차
# - 1. 등분산검정
# - 2. ttest_ind( equal_var=True/False)

m_gr=q1[q1.gender == 'Male']['forehead_ratio'] # 비율 데이터 필터링
f_gr=q1[q1.gender == 'Female']['forehead_ratio']

bartlett(m_gr, f_gr) 
# bartlett의 H0(귀무가설) : 등분산이다
# H1: 이분산이다.
# 결과 p-value = 2.461779...e-48 -> H0 기각
# 결론: 이분산이다

ttest_out = ttest_ind(m_gr,f_gr, equal_var=False)

dir(ttest_out)

-----------------------------------------------------------------------------
# 만약 통계량을 묻는다면
ttest_out.statistic
# 검정을 구하라고하면
ttest_out.pvalue
------------------------------------------------------------------------------

# 문제에서는 통계량의 절대값을 구하라고했으니까
round(abs(ttest_out.statistic),3)

# 기각여부
ttest_out.pvalue < 0.01 # 신뢰수준 99% 에서 기각여부를 결정하라고 했으니 0.05말고 0.01로

# 답: 2.999, Y
```







