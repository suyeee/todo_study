# kafka

> 실시간 스트리밍을 하기위한 플랫폼



분산 스트리밍은 통로가 여러개인것



## 데이터 스트리밍에 대한 구조



### 전통적인구조



(동기적으로 데이터를 받는 경우)

데이터를 획득할때

+ 데이터를 보내는 과정이 필요하고

+ 응답받는 과정이 필요하다

  



(비동기적으로 데이터를 받는 방식)

+ A가 입을 벌리고있고 B가 넣어주는 방식이라고 생각하면 됨.
+ 데이터를 받아올곳 -> Data Source

+ MQ(Message Queue) 를 통과시켜주는 방식
  + 큐의 선입선출 방식으로 인해 먼저 들어간게 먼저나온다.
  + 여기에서의 메세지란 데이터와 똑같은 의미이다.
  + 메세지 = 데이터 = 이벤트





+ 프로토콜이나 포맷도 신경을 써야한다.
  + 그래서 실패지점(Point-of-failure)이 많다.

+ 어디서 장애가 나는지 확인하기 힘들다.



### kafka를 이용한 구조



+ 서로 어떠한 시스템이 어디에 있는지 모름
  + kafka를 통해서만 알수있음
  + 시스템간 의존성을 간접적으로 만들어준다.
+ 데이터를 쌓아내는 방법이라고 생각하면됨.







+ 토픽은 파티션의 추상화된 개념으로 생각하면됨.
+ 실제로 존재하지는 않음. 개념적인 말





+ 프로듀서
  + 프로그램이나 클라이언트로 생각하면됨.
  + 데이터를 흘려보내주는 어플리케이션.





+ 컨슈머
  + 쌓여있는 데이터를 가져와서 활용하게 해주는 역할
  + 그룹핑도 할수있다.
  + 협업의 개념임.
  + 컨슈머도 클라이언트임. 데이터를 가지고오는 어플리케이션이라고 생각하면됨.





## Kafka 구성 요소와 아키텍처



### Topic

> 토픽은 Producer와 Consumer가 소통하는 하나의 채널이라고 볼 수 있다.
>
> Producer -> Topic (데이터 쌓기)
>
> Topic -> Consumer (쌓여있는 데이터 가지고오기)



+ 브로커는 서버라고도 하며, 토픽을 서빙하는 주체가 됩니다.
  + 브로커에 접속하게 해야 토픽에 접속할수있다.
  + 서버 = 노드
+ 토픽은 파티션으로 각각 나뉘게 됩니다. 실제 디스크에 저장되는 기준이 됩니다. 
  + 토픽은 저장방식 이라고 생각하면됨.
+ 파티션은 개념적인 토픽과는 다르게 실제 메시지가 위치하는 공간 입니다.
+ 각 파티션에 메시지가 저장되며, 메시지는 `offset` 이라는 순번을 갖습니다
+ 카프카는 고가용성 및 확장성을 위해 <u>**브로커가 여러 개로 나뉘어서 하나의 토픽을 서빙**</u>할 수있습니다.
+ 하나의 브로커에 여러 토픽이 존재할 수 있고, 하나의 토픽이 여러 브로커에 생길 수 있습니다.



### Zookeeper

+ Zookeeper는 카프카 클러스터들의 여러 요소들을 관리하는 관리자의 역할을 합니다
  + 브로커 관리



### Topic, Partition, Message







+ 하나의 토픽내에 여러개의 파티션이 존재할수가있다.
+ 파티션이라는 폴더 안쪽에 세그먼트라는 파일이 존재한다.







+ 파티션 1의 0번 데이터 =! 파티션 2의 0번데이터
  + 서로 전혀 다른 데이터임.



+ 파티션 마다 commit log가 쌓이게 됩니다.
+ 커밋로그는 삭제,업데이트 전부 안됨. ( 변경못함.)









+ 데이터는 사용자가 지정한 시간만큼만 저장됩니다 .(Retention)
  + 보통 168시간으로 저장
  + 시간을 너무 길게 잡으면 쓸데없는 데이터까지 쌓이게된다.
  + 너무 짧게 잡으면 장애를 대응하기 힘들다.









### Kafka Producer







# 실습1

## 카푸카 설치

```powershell
(base) lab26@ip-000-00-00-0:~$ 
```



카푸카 설치

```powershell
(base) lab26@ip-000-00-00-0:~$ wget https://dlcdn.apache.org/kafka/3.2.0/kafka_2.13-3.2.0.tgz
```

```powershell
(base) lab26@ip-000-00-00-0:~$ ls
SparkCourse  airflow  kafka_2.13-3.2.0.tgz  nohup.out
```



카푸카 압축 풀기

```powershell
(base) lab26@ip-000-00-00-0:~$ tar xvzf kafka_2.13-3.2.0.tgz
```



카푸카 폴더로 접속

```powershell
(base) lab26@ip-000-00-00-0:~$ cd kafka_2.13-3.2.0
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$
```



폴더 목록 확인

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ls
LICENSE  NOTICE  bin  config  libs  licenses  site-docs
```



컨피그 

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ cd config
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0/config$ ls

# 출력결과
connect-console-sink.properties    connect-mirror-maker.properties  server.properties
connect-console-source.properties  connect-standalone.properties    tools-log4j.properties
connect-distributed.properties     consumer.properties              trogdor.conf
connect-file-sink.properties       kraft                            zookeeper.properties
connect-file-source.properties     log4j.properties
connect-log4j.properties           producer.properties
```



설정들 확인하기

`zookeeper.properties` 먼저 확인

```python
# dataDir : zookeeper가 로그를 저장하거나 스냅샷을 저장하는 폴더
dataDir=/tmp/zookeeper
```



```python
# zookeeper가 실행될 포트를 의미, Kafka Broker가 접속하는 포트
clientPort=2126
```



```python
# max Client Connections : 주키퍼에 연결한 브로커의 최대갯수
maxClientCnxns=0
```

브로커의 갯수는 변동이 거의 없는게 좋다. 처음 한번 세팅한 그대로 가는게 좋음. (파티션 때문에)

개발환경에서는 0으로 써도 상관없는데 배포할때는 갯수를 설정해주는게 좋다.



```python
# zookeeper UI 활용 여부
admin.enableServer=false # 우리는 안쓸꺼니까 False로 둔다.
```



터미널에서 진행

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/zookeeper-server-start.sh
USAGE: ./bin/zookeeper-server-start.sh [-daemon] zookeeper.properties
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties # -daemon : 백그라운드에서 돌아가게끔 해주겠다는것.
```



`server.properties`

실행할때마다 브로커 하나씩 생성되는데 그때마다 브로커의 아이디를 유니크하게 만들어줘야됨.

```python
# 브로커의 아이디 설정
broker.id=0
```



```python
# 네크워크로부터 어떠한 요청을 받을때 사용하는 쓰레드 갯수
num.network.threads=3
```



```python
# 로컬적인 처리를 할때 사용할 쓰레드 갯수
# 디스크의 read, write 를 할때 활용할 쓰레드
num.io.threads=8
```



얘네는 안건드리는게 좋음

```python
# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
# 한번에 받을수있는 최대 크기
socket.request.max.bytes=104857600
```



```python
# 브로커에서 사용할 로그들의 저장위치
log.dirs=/tmp/kafka-logs

# 파티션
# 로그들도 전부 분산처리 되어 저장될수있는데 그 로그들을 위한 파티션의 갯수를 의미한다.
num.partitions=1

# 프로듀서가 보낸 데이터들을 저장하고있을 시간 -> 여기를 아마 많이 건들게 될거임
log.retention.hours=168
```



```python
# 세그먼트 -> 1.5GB 정도까지만 가지고있을수있다.
# 이용량을 벗어나면 안됨.
log.segment.bytes=1073741824
```

```python
# 주키퍼 위치
# 혹시 모르니 바꿔준다.
zookeeper.connect=localhost:2181
    
zookeeper.connect=localhost:2126 으로 변경해준다.
```



터미널에서 브로커 실행

카프카 서버 실행

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-server-start.sh -daemon ./config/server.properties 
```



카프카 서버 중지

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-server-stop.sh
```



네트워크 목록? 보기

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ netstat -an | grep 2126
```



토픽 확인하기

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-topics.sh
Create, delete, describe, or change a topic.
Option                                   Description                            
------                                   -----------                            
--alter                                  Alter the number of partitions,        
                                           replica assignment, and/or           
                                           configuration for the topic.         
--at-min-isr-partitions                  if set when describing topics, only    
                                           show partitions whose isr count is   
                                           equal to the configured minimum.     
--bootstrap-server <String: server to    REQUIRED: The Kafka server to connect  
  connect to>                              to.                                  
--command-config <String: command        Property file containing configs to be 
  config property file>                    passed to Admin Client. This is used 
                                           only with --bootstrap-server option  
                                           for describing and altering broker   
                                           configs.                             
--config <String: name=value>            A topic configuration override for the 
                                           topic being created or altered. The  
                                           following is a list of valid         
                                           configurations:                      
                                                cleanup.policy                        
                                                compression.type                      
                                                delete.retention.ms                   
                                                file.delete.delay.ms                  
                                                flush.messages                        
                                                flush.ms                              
                                                follower.replication.throttled.       
                                           replicas                             
                                                index.interval.bytes                  
                                                leader.replication.throttled.replicas 
                                                local.retention.bytes                 
                                                local.retention.ms                    
                                                max.compaction.lag.ms                 
                                                max.message.bytes                     
                                                message.downconversion.enable         
                                                message.format.version                
                                                message.timestamp.difference.max.ms   
                                                message.timestamp.type                
                                                min.cleanable.dirty.ratio             
                                                min.compaction.lag.ms                 
                                                min.insync.replicas                   
                                                preallocate                           
                                                remote.storage.enable                 
                                                retention.bytes                       
                                                retention.ms                          
                                                segment.bytes                         
                                                segment.index.bytes                   
                                                segment.jitter.ms                     
                                                segment.ms                            
                                                unclean.leader.election.enable        
                                         See the Kafka documentation for full   
                                           details on the topic configs. It is  
                                           supported only in combination with --
                                           create if --bootstrap-server option  
                                           is used (the kafka-configs CLI       
                                           supports altering topic configs with 
                                           a --bootstrap-server option).        
--create                                 Create a new topic.                    
--delete                                 Delete a topic                         
--delete-config <String: name>           A topic configuration override to be   
                                           removed for an existing topic (see   
                                           the list of configurations under the 
                                           --config option). Not supported with 
                                           the --bootstrap-server option.       
--describe                               List details for the given topics.     
--disable-rack-aware                     Disable rack aware replica assignment  
--exclude-internal                       exclude internal topics when running   
                                           list or describe command. The        
                                           internal topics will be listed by    
                                           default                              
--help                                   Print usage information.               
--if-exists                              if set when altering or deleting or    
                                           describing topics, the action will   
                                           only execute if the topic exists.    
--if-not-exists                          if set when creating topics, the       
                                           action will only execute if the      
                                           topic does not already exist.        
--list                                   List all available topics.             
--partitions <Integer: # of partitions>  The number of partitions for the topic 
                                           being created or altered (WARNING:   
                                           If partitions are increased for a    
                                           topic that has a key, the partition  
                                           logic or ordering of the messages    
                                           will be affected). If not supplied   
                                           for create, defaults to the cluster  
                                           default.                             
--replica-assignment <String:            A list of manual partition-to-broker   
  broker_id_for_part1_replica1 :           assignments for the topic being      
  broker_id_for_part1_replica2 ,           created or altered.                  
  broker_id_for_part2_replica1 :                                                
  broker_id_for_part2_replica2 , ...>                                           
--replication-factor <Integer:           The replication factor for each        
  replication factor>                      partition in the topic being         
                                           created. If not supplied, defaults   
                                           to the cluster default.              
--topic <String: topic>                  The topic to create, alter, describe   
                                           or delete. It also accepts a regular 
                                           expression, except for --create      
                                           option. Put topic name in double     
                                           quotes and use the '\' prefix to     
                                           escape regular expression symbols; e.
                                           g. "test\.topic".                    
--topic-id <String: topic-id>            The topic-id to describe.This is used  
                                           only with --bootstrap-server option  
                                           for describing topics.               
--topics-with-overrides                  if set when describing topics, only    
                                           show topics that have overridden     
                                           configs                              
--unavailable-partitions                 if set when describing topics, only    
                                           show partitions whose leader is not  
                                           available                            
--under-min-isr-partitions               if set when describing topics, only    
                                           show partitions whose isr count is   
                                           less than the configured minimum.    
--under-replicated-partitions            if set when describing topics, only    
                                           show under replicated partitions     
--version                                Display Kafka version.
```



토픽 생성

위치, 토픽이름, 파티션갯수, 복제 1개 

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic first-lab26-topic --partitions 1 --replication-factor 1
```

출력결과

```powershell
Created topic first-lab26-topic.
```

이렇게 뜨면 잘 만들어진것.



```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092
        
# 출력결과
first-lab26-topic
```



상세정보 확인하기

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-topics.sh --describe --bootstrap-server localhost:9092
        
```



프로듀서 생성

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first-lab26-topic
>
```



컨슈머 생성

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first-lab26-topic
```



```powershell
>hello

hello
```



컨슈머 그룹 확인하기

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

# 출력결과
console-consumer-28319
```



컨슈머 그룹 만들기

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first-lab26-topic --group first-lab26-group
```

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

# 출력결과
first-lab26-group
```



```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group first-lab26-group

# 출력결과
GROUP             TOPIC             PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                           HOST            CLIENT-ID
first-lab26-group first-lab26-topic 0          7               7               0               console-consumer-9c28c52b-3a91-4b26-a375-416ea953b489 /000.00.00.0    console-consumer
```



프로듀서 생성

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first-lab26-topic
        
# 출력결과
>
```



```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first-lab26-topic --group first-lab26-group
```







```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic second-lab26-topic --partitions 2 --replication-factor 1
        
# 출력결과
Created topic second-lab26-topic.
```



터미널 분할해서 양쪽에 똑같이 실행

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic second-lab26-topic
>
```





얘네도 터미널 분할해서 양쪽에서 둘다 실행

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic second-lab26-topic --group second-lab26-group
```





```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-server-stop.sh
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/zookeeper-server-stop.sh
```





`server.properties` 에서 34번줄

```python
listeners=PLAINTEXT://localhost:9026 로 변경
```



서버 다시 실행

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties
    
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-server-start.sh -daemon ./config/server.properties
    
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ netstat -an | grep 2126

(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ netstat -an | grep 9026

```



`server.properties` 에서 62번줄 변경

```python
log.dirs=/tmp/kafka-logs

(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ pwd
/home/lab26/kafka_2.13-3.2.0

log.dirs=/home/lab26/kafka_2.13-3.2.0/tmp/kafka-logs
```



이제 `localhost:9092` 말고 `localhost:9026` 으로 실행

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-topics.sh --create --bootstrap-server localhost:9026 --topic third-lab26-topic --partitions 2 --replication-factor 1

(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-producer.sh --bootstrap-server localhost:9026 --topic third-lab26-topic

(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.2.0$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9026 --topic third-lab26-topic --group third-lab26-group
```





## 카푸카 파이썬 세팅

```powershell
(base) lab26@ip-000-00-00-0:~/kafka_2.13-3.$ cd ..
(base) lab26@ip-000-00-00-0:~$ pwd
/home/lab26
```



```powershell
(base) lab26@ip-000-00-00-0:~$ source activate lab26_env
(lab26_env) lab26@ip-000-00-00-0:~$ pip3 install kafka-python
```

```powershell
(lab26_env) lab26@ip-000-00-00-0:~$ python
Python 3.7.13 (default, Mar 29 2022, 02:18:16) 
[GCC 7.5.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import kafka
>>> kafka
<module 'kafka' from '/home/ubuntu/anaconda3/envs/lab26_env/lib/python3.7/site-packages/kafka/__init__.py'>
>>> exit()
```



```powershell
(lab26_env) lab26@ip-000-00-00-0:~$ mkdir kafka_lab26
```

